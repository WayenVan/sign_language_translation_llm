num_layers: 6

visual_backbone:
  _target_: modules.TimmVisualEncoder
  backbone_id: "resnet18"
  out_channels: 1024

decoder:
  _target_: modules.LlamaCrossDecoder
  hidden_size: 1024
  num_attention_heads: 16
  num_hidden_layers: ${modules.num_layers}
  intermediate_size: 2048 # WARN: not use, because shared_mlp

encoder:
  _target_: modules.SignBertEncoder
  hidden_size: 1024
  num_attention_heads: 16
  num_layers: ${modules.num_layers}
  dropout: 0.1
  max_position_embeddings: 512
  intermediate_size: 2048 # WARN: not use, because shared_mlp

embedding:
  _target_: modules.LLMCompressEmbedding
  num_idx: 2696
  hidden_states: 1024
  llm_hidden_states: 5120

shared_mlp:
  _target_: modules.LlamaMLP
  hidden_size: 1024
  intermediate_size: 2048
  act_fn: silu
